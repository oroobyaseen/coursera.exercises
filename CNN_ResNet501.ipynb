{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN - ResNet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oroobyaseen/coursera.exercises/blob/gh-pages/CNN_ResNet501.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-resnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8uW8Otdjx_Z",
        "outputId": "97beec75-d3a9-4ebc-be23-62cc235d1b5f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-resnet in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from keras-resnet) (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_resnet.models import ResNet50, ResNet101, ResNet152"
      ],
      "metadata": {
        "id": "Yf7W-FTyj37i"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install Keras-Applications"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFXt14YbjhgR",
        "outputId": "1172b4f1-5c2d-405e-e30a-60f7c77a2463"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras-Applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->Keras-Applications) (1.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install adam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu_gDEB6k1zI",
        "outputId": "9a70cea5-c362-438d-9023-b164ccddfe14"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: adam in /usr/local/lib/python3.7/dist-packages (0.0.0.dev0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B722qzWWFb2a"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten\n",
        "from keras_resnet.models import ResNet50, ResNet101, ResNet152\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1MQ8On5iQBx",
        "outputId": "dc03f20d-a081-4eee-dd2a-10120794560e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgd8i2y0m-aW"
      },
      "source": [
        "img_width, img_height = 224, 224"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QhyKT9hjoRJw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Y1A4-xYL38IQ"
      },
      "outputs": [],
      "source": [
        "# Import The Libraries \n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om9VdzlioEO8"
      },
      "source": [
        "# importa o modelo ResNet50 e descarta a Ãºltima camada do classifier.\n",
        "base_model=ResNet50(weights='imagenet',include_top=False, input_shape=(img_width, img_height, 3))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Innt1nZsCRJ",
        "outputId": "2faa944e-d7e2-4c87-fc7f-bc1816bc8c84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wje137UWYT1k"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeRxCPH6Z_GG",
        "outputId": "20787874-a0ed-48c8-a5f3-6486c18082d1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7fa8b61d99d0> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7fa8b61d9510> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61fdd90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa9205c3cd0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa9337a1750> False\n",
            "<keras.layers.convolutional.ZeroPadding2D object at 0x7fa8b620ef10> False\n",
            "<keras.layers.pooling.MaxPooling2D object at 0x7fa8b61d9b90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b62013d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6208950> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b620ac90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6196e50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6196b50> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61a2a50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa920700190> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61a2950> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b62b9d90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b61ae9d0> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b61b79d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61b72d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61b8350> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b61bb890> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61b7590> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61cd510> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b61cd910> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61b29d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61bb1d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa9206790d0> False\n",
            "<keras.layers.merge.Add object at 0x7fa9b1800a90> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa9b18009d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6288f10> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa920624210> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6158f90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6158f50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b615f850> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61683d0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b615cc50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b616ded0> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b6181610> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6184910> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6114250> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6189ed0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b611e310> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6114e50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6121650> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b611e150> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6184bd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b611e050> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6184650> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6132150> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b613a490> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b613ad90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b612a150> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b614d3d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b614de10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6141bd0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b614d450> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b612ab50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60daad0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6141810> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b60f1790> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b60e9950> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60f6a90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6105210> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6102390> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61057d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b614d490> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6144250> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b61447d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60d7790> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b6141b10> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6141450> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6118550> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60f1390> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6158d90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b62088d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b62c5090> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b61a2b90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6114150> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6094750> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b609a810> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b609a110> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60bc990> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60b1e50> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b60b1750> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60bcad0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60c5f90> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b60b6d50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60a7150> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60c5650> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60a1910> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60b6490> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b605eb10> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6052c90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6062f10> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b604f490> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b606da90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b606de90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6052190> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6084f90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b607cbd0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6013ad0> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b6013fd0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6013cd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6079a50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6028dd0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6020e90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa9206181d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60209d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b60c8d50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6062b90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60a79d0> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b60132d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6028810> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6178790> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b61d7e10> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6062b50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60da050> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b61b2410> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6097110> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6037810> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1badb10> False\n",
            "<keras.layers.merge.Add object at 0x7fa8a1bad290> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b6047a10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b6044f10> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1bbed50> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1bbef90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1bbee90> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1bcb890> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1bcbed0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1bcbad0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1bcbd90> False\n",
            "<keras.layers.merge.Add object at 0x7fa8a1bdb810> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1be1190> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1bd73d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1b74f10> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b74b50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b741d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1bd30d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b80f90> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b80f50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1b80690> False\n",
            "<keras.layers.merge.Add object at 0x7fa8a1bd7710> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b8e350> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1ba8dd0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1ba42d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1ba0f10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b6d850> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1bdb050> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1bc3090> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b89fd0> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b7dc50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1ba8b10> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b6097050> False\n",
            "<keras.layers.merge.Add object at 0x7fa8b6084ad0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8b602b750> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8b60bf510> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8b60885d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b36910> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b36a10> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1b41650> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b49c10> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b49510> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1b4f4d0> False\n",
            "<keras.layers.merge.Add object at 0x7fa8a1b65210> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1bcbb50> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b5a2d0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1b65090> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1afd790> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1b69dd0> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1afd7d0> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b07750> False\n",
            "<keras.layers.convolutional.Conv2D object at 0x7fa8a1af2e50> False\n",
            "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7fa8a1af7b10> False\n",
            "<keras.layers.merge.Add object at 0x7fa8a1b21110> False\n",
            "<keras.layers.core.activation.Activation object at 0x7fa8a1b65bd0> False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IqUpAK3tNwO",
        "outputId": "889c1405-5550-4ccf-cc8e-cff74e06fa18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "last_layer = base_model.get_layer('conv5_block3_add')\n",
        "print(last_layer.output_shape)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 7, 7, 2048)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1snymsqtjin"
      },
      "source": [
        "x = Flatten()(last_layer.output)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(3, activation = 'softmax')(x)\n",
        "model = Model(base_model.input, x)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMjGGzLDXzSy",
        "outputId": "2b561857-6bbc-4ee9-e6f4-cbaed1bbe2ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_5[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 100352)       0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         102761472   ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            3075        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 126,352,259\n",
            "Trainable params: 102,764,547\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAk7SIPKj7VG",
        "outputId": "19529dc9-9146-4590-b287-1ce73637b025",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optimizer = Adam(lr=1e-6)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ympDDA6ZHgOh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc9d20a2-ee50-4fd5-8868-935c009b36d7"
      },
      "source": [
        "# Baixar as imagens do exame de citologia cervical\n",
        "!wget -cq https://citologia-cervical.s3-sa-east-1.amazonaws.com/citologia.zip\n",
        "!unzip -qq citologia.zip"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open citologia.zip, citologia.zip.zip or citologia.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "57XIZFty4Cdj"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "train_Path = '/content/drive/MyDrive/New folder (4)/train'\n",
        "test_Path = '/content/drive/MyDrive/New folder (4)/val'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFDwtr2mZSsm"
      },
      "source": [
        "train_datagen=ImageDataGenerator(preprocessing_function = preprocess_input) # incluÃ­do nas dependÃªncias\n",
        "\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNVqXv_lerAX",
        "outputId": "46519353-39cd-43dc-e669-d63da40ad89b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(train_Path,\n",
        "                                                 target_size = (img_width, img_height),\n",
        "                                                 color_mode='rgb',\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',\n",
        "                                                 shuffle=True)\n",
        "\n",
        "validation_set = validation_datagen.flow_from_directory(test_Path,\n",
        "                                                        target_size = (img_width, img_height),\n",
        "                                                        color_mode='rgb',\n",
        "                                                        batch_size = 32,\n",
        "                                                        class_mode = 'categorical',\n",
        "                                                        shuffle=True)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2456 images belonging to 3 classes.\n",
            "Found 616 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_IdEoS9e6bi",
        "outputId": "cbfd506a-66c6-453a-cc2e-fd7633338a19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(training_set,\n",
        "                    steps_per_epoch=len(training_set),\n",
        "                    validation_steps=len(validation_set),\n",
        "                    epochs = 20,\n",
        "                    validation_data = validation_set\n",
        "                    )"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "77/77 [==============================] - ETA: 0s - loss: 0.8082 - accuracy: 0.7972WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
            "77/77 [==============================] - 359s 5s/step - loss: 0.8082 - accuracy: 0.7972 - val_loss: 0.3670 - val_accuracy: 0.8620\n",
            "Epoch 2/20\n",
            "77/77 [==============================] - 36s 462ms/step - loss: 0.5787 - accuracy: 0.8432\n",
            "Epoch 3/20\n",
            "77/77 [==============================] - 36s 468ms/step - loss: 0.4233 - accuracy: 0.8656\n",
            "Epoch 4/20\n",
            "77/77 [==============================] - 36s 465ms/step - loss: 0.3336 - accuracy: 0.8909\n",
            "Epoch 5/20\n",
            "77/77 [==============================] - 36s 466ms/step - loss: 0.2826 - accuracy: 0.9039\n",
            "Epoch 6/20\n",
            "77/77 [==============================] - 36s 470ms/step - loss: 0.2154 - accuracy: 0.9153\n",
            "Epoch 7/20\n",
            "77/77 [==============================] - 36s 470ms/step - loss: 0.2054 - accuracy: 0.9230\n",
            "Epoch 8/20\n",
            "77/77 [==============================] - 37s 479ms/step - loss: 0.1567 - accuracy: 0.9397\n",
            "Epoch 9/20\n",
            "77/77 [==============================] - 36s 473ms/step - loss: 0.1599 - accuracy: 0.9361\n",
            "Epoch 10/20\n",
            "77/77 [==============================] - 36s 468ms/step - loss: 0.1254 - accuracy: 0.9528\n",
            "Epoch 11/20\n",
            "77/77 [==============================] - 36s 463ms/step - loss: 0.1274 - accuracy: 0.9487\n",
            "Epoch 12/20\n",
            "77/77 [==============================] - 36s 472ms/step - loss: 0.1019 - accuracy: 0.9585\n",
            "Epoch 13/20\n",
            "77/77 [==============================] - 36s 462ms/step - loss: 0.0865 - accuracy: 0.9666\n",
            "Epoch 14/20\n",
            "77/77 [==============================] - 36s 468ms/step - loss: 0.0815 - accuracy: 0.9666\n",
            "Epoch 15/20\n",
            "77/77 [==============================] - 36s 466ms/step - loss: 0.0790 - accuracy: 0.9674\n",
            "Epoch 16/20\n",
            "77/77 [==============================] - 36s 471ms/step - loss: 0.0614 - accuracy: 0.9776\n",
            "Epoch 17/20\n",
            "77/77 [==============================] - 37s 480ms/step - loss: 0.0659 - accuracy: 0.9752\n",
            "Epoch 18/20\n",
            "77/77 [==============================] - 36s 471ms/step - loss: 0.0547 - accuracy: 0.9800\n",
            "Epoch 19/20\n",
            "77/77 [==============================] - 37s 473ms/step - loss: 0.0546 - accuracy: 0.9796\n",
            "Epoch 20/20\n",
            "77/77 [==============================] - 36s 466ms/step - loss: 0.0437 - accuracy: 0.9874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQYMKkEqyQXR",
        "outputId": "8408fa86-3630-4afb-b990-a2fb151afb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "source": [
        "# GrÃ¡fico do histÃ³rico do treino\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-03ebe90341f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# GrÃ¡fico do histÃ³rico do treino\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_acc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Irm3fNqYb3a",
        "outputId": "4b0bb0bc-6da4-4c6b-d17a-5b6baaa5e479",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# salvar modelo\n",
        "model.save(\"model.h5\")\n",
        "print(\"Modelo salvo em disco dessa instÃ¢ncia do Google Colab\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo salvo em disco dessa instÃ¢ncia do Google Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOLpDpUtyUgq",
        "outputId": "388f76d3-1ebf-42fa-e15a-2a4b9caad9eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# mÃ©tricas de perda e acurÃ¡cia\n",
        "score = model.evaluate_generator(validation_set, 105)\n",
        "\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[0], score[0]*100))\n",
        "print (\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 699.08%\n",
            "acc: 54.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9OHPmjoEKvB"
      },
      "source": [
        "# carregar modelo salvo no HD\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HteN6bNR2jcw",
        "outputId": "474ae480-8bbb-4808-cbbc-a9a64bb2e955",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 100352)       0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         102761472   flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 3)            3075        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 126,352,259\n",
            "Trainable params: 102,764,547\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffRLj4KKwEO-",
        "outputId": "a5014ee3-87a8-4be5-e595-c02abc82632e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# visualizaÃ§Ã£o das camadas\n",
        "for i, layer in enumerate(model.layers):\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv1_pad\n",
            "2 conv1\n",
            "3 bn_conv1\n",
            "4 activation_1\n",
            "5 pool1_pad\n",
            "6 max_pooling2d_1\n",
            "7 res2a_branch2a\n",
            "8 bn2a_branch2a\n",
            "9 activation_2\n",
            "10 res2a_branch2b\n",
            "11 bn2a_branch2b\n",
            "12 activation_3\n",
            "13 res2a_branch2c\n",
            "14 res2a_branch1\n",
            "15 bn2a_branch2c\n",
            "16 bn2a_branch1\n",
            "17 add_1\n",
            "18 activation_4\n",
            "19 res2b_branch2a\n",
            "20 bn2b_branch2a\n",
            "21 activation_5\n",
            "22 res2b_branch2b\n",
            "23 bn2b_branch2b\n",
            "24 activation_6\n",
            "25 res2b_branch2c\n",
            "26 bn2b_branch2c\n",
            "27 add_2\n",
            "28 activation_7\n",
            "29 res2c_branch2a\n",
            "30 bn2c_branch2a\n",
            "31 activation_8\n",
            "32 res2c_branch2b\n",
            "33 bn2c_branch2b\n",
            "34 activation_9\n",
            "35 res2c_branch2c\n",
            "36 bn2c_branch2c\n",
            "37 add_3\n",
            "38 activation_10\n",
            "39 res3a_branch2a\n",
            "40 bn3a_branch2a\n",
            "41 activation_11\n",
            "42 res3a_branch2b\n",
            "43 bn3a_branch2b\n",
            "44 activation_12\n",
            "45 res3a_branch2c\n",
            "46 res3a_branch1\n",
            "47 bn3a_branch2c\n",
            "48 bn3a_branch1\n",
            "49 add_4\n",
            "50 activation_13\n",
            "51 res3b_branch2a\n",
            "52 bn3b_branch2a\n",
            "53 activation_14\n",
            "54 res3b_branch2b\n",
            "55 bn3b_branch2b\n",
            "56 activation_15\n",
            "57 res3b_branch2c\n",
            "58 bn3b_branch2c\n",
            "59 add_5\n",
            "60 activation_16\n",
            "61 res3c_branch2a\n",
            "62 bn3c_branch2a\n",
            "63 activation_17\n",
            "64 res3c_branch2b\n",
            "65 bn3c_branch2b\n",
            "66 activation_18\n",
            "67 res3c_branch2c\n",
            "68 bn3c_branch2c\n",
            "69 add_6\n",
            "70 activation_19\n",
            "71 res3d_branch2a\n",
            "72 bn3d_branch2a\n",
            "73 activation_20\n",
            "74 res3d_branch2b\n",
            "75 bn3d_branch2b\n",
            "76 activation_21\n",
            "77 res3d_branch2c\n",
            "78 bn3d_branch2c\n",
            "79 add_7\n",
            "80 activation_22\n",
            "81 res4a_branch2a\n",
            "82 bn4a_branch2a\n",
            "83 activation_23\n",
            "84 res4a_branch2b\n",
            "85 bn4a_branch2b\n",
            "86 activation_24\n",
            "87 res4a_branch2c\n",
            "88 res4a_branch1\n",
            "89 bn4a_branch2c\n",
            "90 bn4a_branch1\n",
            "91 add_8\n",
            "92 activation_25\n",
            "93 res4b_branch2a\n",
            "94 bn4b_branch2a\n",
            "95 activation_26\n",
            "96 res4b_branch2b\n",
            "97 bn4b_branch2b\n",
            "98 activation_27\n",
            "99 res4b_branch2c\n",
            "100 bn4b_branch2c\n",
            "101 add_9\n",
            "102 activation_28\n",
            "103 res4c_branch2a\n",
            "104 bn4c_branch2a\n",
            "105 activation_29\n",
            "106 res4c_branch2b\n",
            "107 bn4c_branch2b\n",
            "108 activation_30\n",
            "109 res4c_branch2c\n",
            "110 bn4c_branch2c\n",
            "111 add_10\n",
            "112 activation_31\n",
            "113 res4d_branch2a\n",
            "114 bn4d_branch2a\n",
            "115 activation_32\n",
            "116 res4d_branch2b\n",
            "117 bn4d_branch2b\n",
            "118 activation_33\n",
            "119 res4d_branch2c\n",
            "120 bn4d_branch2c\n",
            "121 add_11\n",
            "122 activation_34\n",
            "123 res4e_branch2a\n",
            "124 bn4e_branch2a\n",
            "125 activation_35\n",
            "126 res4e_branch2b\n",
            "127 bn4e_branch2b\n",
            "128 activation_36\n",
            "129 res4e_branch2c\n",
            "130 bn4e_branch2c\n",
            "131 add_12\n",
            "132 activation_37\n",
            "133 res4f_branch2a\n",
            "134 bn4f_branch2a\n",
            "135 activation_38\n",
            "136 res4f_branch2b\n",
            "137 bn4f_branch2b\n",
            "138 activation_39\n",
            "139 res4f_branch2c\n",
            "140 bn4f_branch2c\n",
            "141 add_13\n",
            "142 activation_40\n",
            "143 res5a_branch2a\n",
            "144 bn5a_branch2a\n",
            "145 activation_41\n",
            "146 res5a_branch2b\n",
            "147 bn5a_branch2b\n",
            "148 activation_42\n",
            "149 res5a_branch2c\n",
            "150 res5a_branch1\n",
            "151 bn5a_branch2c\n",
            "152 bn5a_branch1\n",
            "153 add_14\n",
            "154 activation_43\n",
            "155 res5b_branch2a\n",
            "156 bn5b_branch2a\n",
            "157 activation_44\n",
            "158 res5b_branch2b\n",
            "159 bn5b_branch2b\n",
            "160 activation_45\n",
            "161 res5b_branch2c\n",
            "162 bn5b_branch2c\n",
            "163 add_15\n",
            "164 activation_46\n",
            "165 res5c_branch2a\n",
            "166 bn5c_branch2a\n",
            "167 activation_47\n",
            "168 res5c_branch2b\n",
            "169 bn5c_branch2b\n",
            "170 activation_48\n",
            "171 res5c_branch2c\n",
            "172 bn5c_branch2c\n",
            "173 add_16\n",
            "174 activation_49\n",
            "175 flatten_1\n",
            "176 dense_1\n",
            "177 dropout_1\n",
            "178 dense_2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98HRlkG-kma0"
      },
      "source": [
        "for layer in model.layers[:167]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[167:]:\n",
        "   layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9jVc0jDeclT"
      },
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.000001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq6YPmVHE6vY",
        "outputId": "686b02d9-77c3-4357-b707-2b8c8fce0267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from keras.callbacks import *\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/log/resnet50:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlVXgvrsFnT2"
      },
      "source": [
        "# Carregando o modelo com o peso melhor treinado (exemplo: carregando epoch 47, validation accuracy de 90.5%)\n",
        "\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/log/resnet50:030-val_acc:0.629.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNpLw-cYpsgY",
        "outputId": "1c573474-decc-4aef-a748-d07598a69e8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Fine-tune\n",
        "history = model.fit_generator(training_set,\n",
        "                    steps_per_epoch=528/32,\n",
        "                    epochs = 100,\n",
        "                    validation_data = validation_set,\n",
        "                    validation_steps = 105/32,\n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/16 [==============================] - 8s 497ms/step - loss: 0.0274 - acc: 0.9963 - val_loss: 7.0440 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00001: val_acc did not improve from 0.61905\n",
            "Epoch 2/100\n",
            "17/16 [==============================] - 3s 186ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 6.8002 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.61905\n",
            "Epoch 3/100\n",
            "17/16 [==============================] - 4s 226ms/step - loss: 1.4234e-04 - acc: 1.0000 - val_loss: 6.7798 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.61905\n",
            "Epoch 4/100\n",
            "17/16 [==============================] - 4s 254ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 6.9305 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.61905\n",
            "Epoch 5/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.1040 - acc: 0.9920 - val_loss: 7.9186 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.61905\n",
            "Epoch 6/100\n",
            "17/16 [==============================] - 4s 251ms/step - loss: 1.0431e-05 - acc: 1.0000 - val_loss: 5.9299 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.61905\n",
            "Epoch 7/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0178 - acc: 0.9982 - val_loss: 7.3513 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.61905\n",
            "Epoch 8/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 0.0082 - acc: 0.9963 - val_loss: 6.5977 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.61905\n",
            "Epoch 9/100\n",
            "17/16 [==============================] - 4s 239ms/step - loss: 0.0123 - acc: 0.9982 - val_loss: 6.9440 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.61905\n",
            "Epoch 10/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0066 - acc: 0.9963 - val_loss: 6.4831 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.61905\n",
            "Epoch 11/100\n",
            "17/16 [==============================] - 4s 253ms/step - loss: 0.0334 - acc: 0.9963 - val_loss: 7.4857 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.61905\n",
            "Epoch 12/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0459 - acc: 0.9901 - val_loss: 7.4636 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.61905\n",
            "Epoch 13/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 7.0304 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.61905\n",
            "Epoch 14/100\n",
            "17/16 [==============================] - 4s 237ms/step - loss: 0.0937 - acc: 0.9908 - val_loss: 7.1070 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.61905\n",
            "Epoch 15/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 0.0045 - acc: 0.9982 - val_loss: 6.9665 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.61905\n",
            "Epoch 16/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 0.0019 - acc: 0.9982 - val_loss: 7.2456 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.61905\n",
            "Epoch 17/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0293 - acc: 0.9945 - val_loss: 6.2312 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.61905\n",
            "Epoch 18/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 0.0466 - acc: 0.9963 - val_loss: 6.8021 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.61905\n",
            "Epoch 19/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 7.4838 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.61905\n",
            "Epoch 20/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 0.0128 - acc: 0.9982 - val_loss: 6.5623 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.61905\n",
            "Epoch 21/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0347 - acc: 0.9963 - val_loss: 7.5980 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.61905\n",
            "Epoch 22/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0457 - acc: 0.9945 - val_loss: 6.5441 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.61905\n",
            "Epoch 23/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 0.1297 - acc: 0.9920 - val_loss: 7.1499 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.61905\n",
            "Epoch 24/100\n",
            "17/16 [==============================] - 4s 251ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 7.4527 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.61905\n",
            "Epoch 25/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 1.4206e-07 - acc: 1.0000 - val_loss: 6.1881 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.61905\n",
            "Epoch 26/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 7.6127 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.61905\n",
            "Epoch 27/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 1.2523e-05 - acc: 1.0000 - val_loss: 7.2235 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.61905\n",
            "Epoch 28/100\n",
            "17/16 [==============================] - 4s 239ms/step - loss: 0.1570 - acc: 0.9821 - val_loss: 7.1340 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.61905\n",
            "Epoch 29/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 6.5412 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.61905\n",
            "Epoch 30/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.1296 - acc: 0.9920 - val_loss: 7.5656 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.61905\n",
            "Epoch 31/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.1481 - acc: 0.9901 - val_loss: 6.3656 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00031: val_acc did not improve from 0.61905\n",
            "Epoch 32/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0919 - acc: 0.9926 - val_loss: 7.0569 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.61905\n",
            "Epoch 33/100\n",
            "17/16 [==============================] - 4s 240ms/step - loss: 2.2456e-05 - acc: 1.0000 - val_loss: 6.6664 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.61905\n",
            "Epoch 34/100\n",
            "17/16 [==============================] - 4s 253ms/step - loss: 2.1917e-05 - acc: 1.0000 - val_loss: 7.7196 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.61905\n",
            "Epoch 35/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0684 - acc: 0.9945 - val_loss: 6.4245 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.61905\n",
            "Epoch 36/100\n",
            "17/16 [==============================] - 4s 250ms/step - loss: 0.0250 - acc: 0.9963 - val_loss: 7.4404 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.61905\n",
            "Epoch 37/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 0.0387 - acc: 0.9963 - val_loss: 6.2511 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.61905\n",
            "Epoch 38/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 1.4878e-04 - acc: 1.0000 - val_loss: 8.0578 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.61905\n",
            "Epoch 39/100\n",
            "17/16 [==============================] - 4s 244ms/step - loss: 1.1176e-05 - acc: 1.0000 - val_loss: 6.6903 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.61905\n",
            "Epoch 40/100\n",
            "17/16 [==============================] - 4s 250ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 5.7745 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.61905\n",
            "Epoch 41/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 6.8352e-04 - acc: 1.0000 - val_loss: 8.4288 - val_acc: 0.4476\n",
            "\n",
            "Epoch 00041: val_acc did not improve from 0.61905\n",
            "Epoch 42/100\n",
            "17/16 [==============================] - 4s 233ms/step - loss: 0.0099 - acc: 0.9982 - val_loss: 6.6908 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00042: val_acc did not improve from 0.61905\n",
            "Epoch 43/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0565 - acc: 0.9963 - val_loss: 6.9764 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00043: val_acc did not improve from 0.61905\n",
            "Epoch 44/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 1.0666e-05 - acc: 1.0000 - val_loss: 6.2354 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00044: val_acc did not improve from 0.61905\n",
            "Epoch 45/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 0.0031 - acc: 0.9982 - val_loss: 8.6647 - val_acc: 0.4476\n",
            "\n",
            "Epoch 00045: val_acc did not improve from 0.61905\n",
            "Epoch 46/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0156 - acc: 0.9963 - val_loss: 6.4073 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00046: val_acc did not improve from 0.61905\n",
            "Epoch 47/100\n",
            "17/16 [==============================] - 4s 238ms/step - loss: 0.0298 - acc: 0.9982 - val_loss: 6.6655 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00047: val_acc did not improve from 0.61905\n",
            "Epoch 48/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 1.1943e-07 - acc: 1.0000 - val_loss: 7.0133 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00048: val_acc did not improve from 0.61905\n",
            "Epoch 49/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 2.8578e-05 - acc: 1.0000 - val_loss: 7.4209 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00049: val_acc did not improve from 0.61905\n",
            "Epoch 50/100\n",
            "17/16 [==============================] - 4s 242ms/step - loss: 0.1579 - acc: 0.9883 - val_loss: 6.8582 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00050: val_acc did not improve from 0.61905\n",
            "Epoch 51/100\n",
            "17/16 [==============================] - 4s 235ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.2855 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00051: val_acc did not improve from 0.61905\n",
            "Epoch 52/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 2.5971e-06 - acc: 1.0000 - val_loss: 7.3924 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00052: val_acc did not improve from 0.61905\n",
            "Epoch 53/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0023 - acc: 0.9982 - val_loss: 7.0017 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00053: val_acc did not improve from 0.61905\n",
            "Epoch 54/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 2.1622e-07 - acc: 1.0000 - val_loss: 7.5901 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00054: val_acc did not improve from 0.61905\n",
            "Epoch 55/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.0588 - val_acc: 0.6095\n",
            "\n",
            "Epoch 00055: val_acc did not improve from 0.61905\n",
            "Epoch 56/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 0.0075 - acc: 0.9963 - val_loss: 7.3945 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00056: val_acc did not improve from 0.61905\n",
            "Epoch 57/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0549 - acc: 0.9945 - val_loss: 6.6284 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00057: val_acc did not improve from 0.61905\n",
            "Epoch 58/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 4.8086e-04 - acc: 1.0000 - val_loss: 7.2020 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00058: val_acc did not improve from 0.61905\n",
            "Epoch 59/100\n",
            "17/16 [==============================] - 4s 242ms/step - loss: 0.0291 - acc: 0.9982 - val_loss: 6.6959 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00059: val_acc did not improve from 0.61905\n",
            "Epoch 60/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 6.1213e-04 - acc: 1.0000 - val_loss: 7.5973 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00060: val_acc did not improve from 0.61905\n",
            "Epoch 61/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.7843 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00061: val_acc did not improve from 0.61905\n",
            "Epoch 62/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0891 - acc: 0.9945 - val_loss: 6.9105 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00062: val_acc did not improve from 0.61905\n",
            "Epoch 63/100\n",
            "17/16 [==============================] - 4s 251ms/step - loss: 0.0225 - acc: 0.9982 - val_loss: 7.2644 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00063: val_acc did not improve from 0.61905\n",
            "Epoch 64/100\n",
            "17/16 [==============================] - 4s 250ms/step - loss: 0.0811 - acc: 0.9945 - val_loss: 7.1765 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00064: val_acc did not improve from 0.61905\n",
            "Epoch 65/100\n",
            "17/16 [==============================] - 4s 235ms/step - loss: 5.9817e-05 - acc: 1.0000 - val_loss: 6.4869 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00065: val_acc did not improve from 0.61905\n",
            "Epoch 66/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0424 - acc: 0.9963 - val_loss: 6.9713 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00066: val_acc did not improve from 0.61905\n",
            "Epoch 67/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 4.9226e-05 - acc: 1.0000 - val_loss: 7.6776 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00067: val_acc did not improve from 0.61905\n",
            "Epoch 68/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0518 - acc: 0.9945 - val_loss: 5.8621 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00068: val_acc did not improve from 0.61905\n",
            "Epoch 69/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0390 - acc: 0.9963 - val_loss: 7.4842 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00069: val_acc did not improve from 0.61905\n",
            "Epoch 70/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 6.9970e-04 - acc: 1.0000 - val_loss: 7.2686 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00070: val_acc did not improve from 0.61905\n",
            "Epoch 71/100\n",
            "17/16 [==============================] - 4s 244ms/step - loss: 1.3305e-07 - acc: 1.0000 - val_loss: 6.6151 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00071: val_acc did not improve from 0.61905\n",
            "Epoch 72/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 0.0594 - acc: 0.9963 - val_loss: 7.3681 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00072: val_acc did not improve from 0.61905\n",
            "Epoch 73/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0170 - acc: 0.9982 - val_loss: 7.5526 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00073: val_acc did not improve from 0.61905\n",
            "Epoch 74/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.1485 - val_acc: 0.6190\n",
            "\n",
            "Epoch 00074: val_acc improved from 0.61905 to 0.61905, saving model to /content/drive/My Drive/Colab Notebooks/log/resnet50:074-val_acc:0.619.hdf5\n",
            "Epoch 75/100\n",
            "17/16 [==============================] - 3s 192ms/step - loss: 0.0523 - acc: 0.9920 - val_loss: 6.7109 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00075: val_acc did not improve from 0.61905\n",
            "Epoch 76/100\n",
            "17/16 [==============================] - 4s 248ms/step - loss: 0.0049 - acc: 0.9982 - val_loss: 7.8927 - val_acc: 0.4952\n",
            "\n",
            "Epoch 00076: val_acc did not improve from 0.61905\n",
            "Epoch 77/100\n",
            "17/16 [==============================] - 4s 252ms/step - loss: 0.0401 - acc: 0.9963 - val_loss: 6.5027 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00077: val_acc did not improve from 0.61905\n",
            "Epoch 78/100\n",
            "17/16 [==============================] - 5s 265ms/step - loss: 0.2110 - acc: 0.9864 - val_loss: 6.4155 - val_acc: 0.5810\n",
            "\n",
            "Epoch 00078: val_acc did not improve from 0.61905\n",
            "Epoch 79/100\n",
            "17/16 [==============================] - 4s 251ms/step - loss: 5.7717e-05 - acc: 1.0000 - val_loss: 7.6474 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00079: val_acc did not improve from 0.61905\n",
            "Epoch 80/100\n",
            "17/16 [==============================] - 4s 261ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 6.9637 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00080: val_acc did not improve from 0.61905\n",
            "Epoch 81/100\n",
            "17/16 [==============================] - 4s 256ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 6.7515 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00081: val_acc did not improve from 0.61905\n",
            "Epoch 82/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 0.0594 - acc: 0.9963 - val_loss: 6.9077 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00082: val_acc did not improve from 0.61905\n",
            "Epoch 83/100\n",
            "17/16 [==============================] - 4s 249ms/step - loss: 0.0146 - acc: 0.9982 - val_loss: 7.1121 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00083: val_acc did not improve from 0.61905\n",
            "Epoch 84/100\n",
            "17/16 [==============================] - 4s 238ms/step - loss: 0.0596 - acc: 0.9963 - val_loss: 7.2628 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00084: val_acc did not improve from 0.61905\n",
            "Epoch 85/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 0.0335 - acc: 0.9963 - val_loss: 7.0107 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00085: val_acc did not improve from 0.61905\n",
            "Epoch 86/100\n",
            "17/16 [==============================] - 4s 244ms/step - loss: 1.2185e-07 - acc: 1.0000 - val_loss: 7.0984 - val_acc: 0.5524\n",
            "\n",
            "Epoch 00086: val_acc did not improve from 0.61905\n",
            "Epoch 87/100\n",
            "17/16 [==============================] - 4s 245ms/step - loss: 0.0709 - acc: 0.9920 - val_loss: 7.0000 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00087: val_acc did not improve from 0.61905\n",
            "Epoch 88/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.7578 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00088: val_acc did not improve from 0.61905\n",
            "Epoch 89/100\n",
            "17/16 [==============================] - 4s 236ms/step - loss: 0.1297 - acc: 0.9920 - val_loss: 6.7197 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00089: val_acc did not improve from 0.61905\n",
            "Epoch 90/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 7.8798 - val_acc: 0.4857\n",
            "\n",
            "Epoch 00090: val_acc did not improve from 0.61905\n",
            "Epoch 91/100\n",
            "17/16 [==============================] - 4s 244ms/step - loss: 5.9090e-07 - acc: 1.0000 - val_loss: 6.2916 - val_acc: 0.6000\n",
            "\n",
            "Epoch 00091: val_acc did not improve from 0.61905\n",
            "Epoch 92/100\n",
            "17/16 [==============================] - 4s 242ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 6.7208 - val_acc: 0.5619\n",
            "\n",
            "Epoch 00092: val_acc did not improve from 0.61905\n",
            "Epoch 93/100\n",
            "17/16 [==============================] - 4s 234ms/step - loss: 0.0075 - acc: 0.9982 - val_loss: 6.9942 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00093: val_acc did not improve from 0.61905\n",
            "Epoch 94/100\n",
            "17/16 [==============================] - 4s 241ms/step - loss: 1.6206e-07 - acc: 1.0000 - val_loss: 7.7719 - val_acc: 0.5048\n",
            "\n",
            "Epoch 00094: val_acc did not improve from 0.61905\n",
            "Epoch 95/100\n",
            "17/16 [==============================] - 4s 247ms/step - loss: 2.5766e-06 - acc: 1.0000 - val_loss: 6.4093 - val_acc: 0.5714\n",
            "\n",
            "Epoch 00095: val_acc did not improve from 0.61905\n",
            "Epoch 96/100\n",
            "17/16 [==============================] - 4s 241ms/step - loss: 0.1542 - acc: 0.9901 - val_loss: 7.5794 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00096: val_acc did not improve from 0.61905\n",
            "Epoch 97/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 1.1921e-07 - acc: 1.0000 - val_loss: 6.9122 - val_acc: 0.5333\n",
            "\n",
            "Epoch 00097: val_acc did not improve from 0.61905\n",
            "Epoch 98/100\n",
            "17/16 [==============================] - 4s 237ms/step - loss: 0.0494 - acc: 0.9963 - val_loss: 7.1241 - val_acc: 0.5429\n",
            "\n",
            "Epoch 00098: val_acc did not improve from 0.61905\n",
            "Epoch 99/100\n",
            "17/16 [==============================] - 4s 246ms/step - loss: 0.0297 - acc: 0.9982 - val_loss: 6.3319 - val_acc: 0.5905\n",
            "\n",
            "Epoch 00099: val_acc did not improve from 0.61905\n",
            "Epoch 100/100\n",
            "17/16 [==============================] - 4s 243ms/step - loss: 0.0304 - acc: 0.9982 - val_loss: 7.3348 - val_acc: 0.5143\n",
            "\n",
            "Epoch 00100: val_acc did not improve from 0.61905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nofs42xG1SjS"
      },
      "source": [
        "model.save(\"model.h5\")\n",
        "uploaded = drive.CreateFile({'title': 'model.h5'})\n",
        "uploaded.SetContentFile('model.h5')\n",
        "uploaded.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioiqswgAqS5f",
        "outputId": "64f7eb52-a863-4006-8bff-08278b68f7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# listar todos os dados no history\n",
        "print(history.history.keys())\n",
        "# GrÃ¡fico de treino - acurÃ¡cia\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# GrÃ¡fico de treino - perda\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAFUFBRFUZQA/x/xq3y0akRqcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXd4XFeZ/z9n1HuzLFuSbdmO48RJ\n3JM4BTaN9EIJoSULLLuBXRZCy5IsbdnfsssuLCWUQICwLCULJIEEEkIKToFUx3Ec23Hc4iJZlmT1\nXs/vj/cezZ3RjDSyNFa57+d59Ixm5s6957bvec/3vOdcY61FURRFmf2EproAiqIoyvFBBV9RFCUg\nqOAriqIEBBV8RVGUgKCCryiKEhBU8BVFUQKCCr6iAMaY/zHG/FuCy+43xlw00fUoyvFGBV9RFCUg\nqOAriqIEBBV8ZcbgWSk3G2O2GmM6jTE/MsaUGWP+YIxpN8Y8aowp8i1/tTFmuzGmxRjzuDHmZN93\na4wxm73f/RLIjNrWlcaYLd5vnzbGrDzGMv+dMWaPMabJGHO/Mabc+9wYY75ujKk3xrQZY14xxpzq\nfXe5MWaHV7YaY8ynjumAKUoUKvjKTONtwJuAE4GrgD8A/wyUItfzRwGMMScCdwEf8757EPidMSbd\nGJMO/Bb4KVAM/NpbL95v1wB3Ah8ESoDvA/cbYzLGU1BjzAXAfwDXAfOBA8D/eV9fDLzR248Cb5lG\n77sfAR+01uYBpwJ/Gs92FSUeKvjKTONb1to6a20N8BTwnLX2JWttD/AbYI233DuAB6y1j1hr+4Gv\nAlnA2cAGIA34hrW231p7N/CCbxs3At+31j5nrR201v4E6PV+Nx7eA9xprd1sre0FbgXOMsZUAf1A\nHnASYKy1r1pra73f9QMrjDH51tpma+3mcW5XUWKigq/MNOp8/3fHeJ/r/V+ORNQAWGuHgENAhfdd\njY2cOfCA7/9FwCc9O6fFGNMCLPB+Nx6iy9CBRPEV1to/Ad8GvgPUG2PuMMbke4u+DbgcOGCMecIY\nc9Y4t6soMVHBV2YrhxHhBsQzR0S7BqgFKrzPHAt9/x8CvmStLfT9ZVtr75pgGXIQi6gGwFp7m7V2\nHbACsXZu9j5/wVp7DTAXsZ5+Nc7tKkpMVPCV2cqvgCuMMRcaY9KATyK2zNPAM8AA8FFjTJox5q3A\nGb7f/gD4kDHmTK9zNccYc4UxJm+cZbgLeL8xZrXn//87YkHtN8ac7q0/DegEeoAhr4/hPcaYAs+K\nagOGJnAcFGUYFXxlVmKtfQ24HvgWcBTp4L3KWttnre0D3gq8D2hC/P57fb/dBPwdYrk0A3u8Zcdb\nhkeBzwH3IK2KpcA7va/zkYqlGbF9GoGveN/dAOw3xrQBH0L6AhRlwhh9AIqiKEow0AhfURQlIKjg\nK4qiBAQVfEVRlICggq8oihIQUqe6AH7mzJljq6qqproYiqIoM4YXX3zxqLW2NJFlp5XgV1VVsWnT\npqkuhqIoyozBGHNg7KUEtXQURVECggq+oihKQFDBVxRFCQjTysOPRX9/P9XV1fT09Ex1UZJKZmYm\nlZWVpKWlTXVRFEWZpUx7wa+uriYvL4+qqioiJzecPVhraWxspLq6msWLF091cRRFmaVMe0unp6eH\nkpKSWSv2AMYYSkpKZn0rRlGUqWXaCz4wq8XeEYR9VBRlapkRgq8ox8yRbXDgmakuhaJMC1Twx6Cl\npYXvfve74/7d5ZdfTktLSxJKpIyLjV+CBz4x1aVQlGmBCv4YxBP8gYGBUX/34IMPUlhYmKxiKYnS\n3QLdzVNdCkWZFkz7LJ2p5pZbbmHv3r2sXr2atLQ0MjMzKSoqYufOnezatYs3v/nNHDp0iJ6eHm66\n6SZuvPFGIDxNREdHB5dddhnnnnsuTz/9NBUVFdx3331kZWVN8Z4FhN526Gmb6lIoyrRgRgn+F3+3\nnR2HJ/fmXVGezxeuOiXu91/+8pfZtm0bW7Zs4fHHH+eKK65g27Ztw+mTd955J8XFxXR3d3P66afz\ntre9jZKSkoh17N69m7vuuosf/OAHXHfdddxzzz1cf/31k7ofShx626C/EwYHIGVGXe6KMumopTNO\nzjjjjIhc+dtuu41Vq1axYcMGDh06xO7du0f8ZvHixaxevRqAdevWsX///uNV3NnHYD8MjeOZ3r1t\nka+KEmBmVMgzWiR+vMjJyRn+//HHH+fRRx/lmWeeITs7m/POOy9mLn1GRsbw/ykpKXR3dx+Xss46\nrIVvroZzPwZn/F1iy/e2y/89rZBdnNzyKco0RyP8McjLy6O9vT3md62trRQVFZGdnc3OnTt59tln\nj3PpAsZAL7RVQ/2rCS7fA0Ne57pG+IoysyL8qaCkpIRzzjmHU089laysLMrKyoa/u/TSS/ne977H\nySefzPLly9mwYcMUljQA9HXIa1djYsv3+ipq7bhVFBX8RPjFL34R8/OMjAz+8Ic/xPzO+fRz5sxh\n27Ztw59/6lOfmvTyBQYn4Mck+K2TXx5FmWGopaPMHIYj/KbElveLvFo6iqKCr8wgetXSUZSJoIKv\nzBxchN/dJBk4Y+EXfI3wFSW5gm+M+bgxZrsxZpsx5i5jTGYyt6fMcpyAD/aFxT+R5UE9fEUhiYJv\njKkAPgqst9aeCqQA70zW9pQZzkAvPPw5mfsmHn6RT8TWcYKfkq6Crygk39JJBbKMMalANnA4ydtT\nZirVm+Dp22DvY/GX6R2v4Hsin1+ulo6ikETBt9bWAF8FDgK1QKu19uHo5YwxNxpjNhljNjU0NCSr\nOMfMsU6PDPCNb3yDrq6uSS7RLKXby7xpr4u/TESEn0CmTm87pGRATql22ioKybV0ioBrgMVAOZBj\njBkxY5i19g5r7Xpr7frS0tJkFSeS/p7IaHEUVPCPE07A22vjL+P35BO1dDLyICNfLR1FIbmWzkXA\n69baBmttP3AvcHYSt5c4bTXQcjChRf3TI99888185Stf4fTTT2flypV84QtfAKCzs5MrrriCVatW\nceqpp/LLX/6S2267jcOHD3P++edz/vnnJ3NvZgcuwu8YI8JPSZf/E43wM/IgM18tnang8Bb48eXQ\nNwOCnu4WeOprMDQ41SVJKskcaXsQ2GCMyQa6gQuBTRNa4x9ugSOvTLxk/Z2S1peeC/NOg8u+HHdR\n//TIDz/8MHfffTfPP/881lquvvpqnnzySRoaGigvL+eBBx4AZI6dgoICvva1r7Fx40bmzJkz8TLP\ndoYj/CPxl+ntgLx50Fozvgg/s0Atnalg3+Nw4C/QuAfmr5zq0ozOq7+Dx74ISy+A8tVTXZqkkUwP\n/zngbmAz8Iq3rTuStb3EsV4Ot/tLnIcffpiHH36YNWvWsHbtWnbu3Mnu3bs57bTTeOSRR/j0pz/N\nU089RUFBQVJKPqtJNMLPyJdZLxMR/J42EXu1dKaGthp57aif2nIkQmu1vHYdTfw3/d2JjQeZRiR1\nLh1r7ReAL0zaCkeJxBNmoA/qt8v/806DUOKHwFrLrbfeygc/+MER323evJkHH3yQz372s1x44YV8\n/vOfn3hZg0SX9xjCUSP8dmmVZQ8kHuEXLhBLZ7BXUj9TM8b+nTI5OBHtGOWcThdcWTsTFPy+Lvj6\nCrj4S7DmPckr1yQTvJG2g73h/xPw6/zTI19yySXceeeddHRIh29NTQ319fUcPnyY7Oxsrr/+em6+\n+WY2b9484reBY8f98D9XJh4BOQHvaZHIKRZ9HZCRC9klCXr4bZ6l4z1bWG2d44sT0dEq8elC6yF5\n7UwwU7DhVXlWcv2O5JUpCQRvtsyBvvD/CQi+f3rkyy67jHe/+92cddZZAOTm5vKzn/2MPXv2cPPN\nNxMKhUhLS+P2228H4MYbb+TSSy+lvLycjRs3JmV3pi17HoX9T8lNkciDR7p9At5RB0VVI5fp7YDC\nRZCWBUf3jL1Of5YOSAWQe5wywaYj/T3wwwvhws/DiZckf3vDls4oNh1A3XYoPRlCUxh/Dkf4CQq+\neybDTKjMfARP8CMi/IGEfhI9PfJNN90U8X7p0qVccsnIG+gjH/kIH/nIR8ZfxkQYGpSIN/MY+wu2\n3CU3fbKeAuWyoNprE9tGVxMULITWg5KLH0vwXYQfSoWu50Zfn3valcvSAWk9zBQGB+RaTc8Ze9lE\nqd8OddtkkFuyBb+/O9xqG00Um/bB7WfD234Ep12b3DLFw9pw5dSZ4MR8dV5kP8MEP3iWzoBP8O0M\nTsHa/BP4xmkStY2XloPw2w/BX76R+G+ObIPGvePYxgF5bRslr95hrbQE5p4s7+N5vr0dkJ4HWcVj\nT6A20AND/RLduwg/2ZbOYD987w2w/bcTX9dTXxUhnMxOwdqt8tqd4PTSozE0GN96A2jzDaofLcJv\n2iev1S9MvEzHSlejXC8wjgjfE/xY1+qTX4Vdf5ycsk0ywRP8wT5I9eZwm8k5t4e3SOaJ8x7Hg4tK\ntt2b+APB770R/vDpxJYdGoQWr1yjDaRy9LRK5esEP9ZoW2sjPfyhgdFz690gLZeWCcnPxT+yVf4O\nPT/xdVW/AM37ExegRHApzYk+TyAe1sKv/hp+cEH8ZZxFkjtvdMF3FUPtyxMr00Rw95AJHYOlE7Vv\n1sJT/w3PfW/yyjeJzAjBt5MZ5Qz0Qlq2/J+gpROXoSFpCrbXiWj5Ww/jJO4+1r4sOcLRuAi6+cD4\nN+ZuwNZDiUVW1kokluBgNdprJbp2/4+FizjnLBO7JtZv+joBb+xEdol8NlqmzrDg5/ssnSQL/kHP\nZpoMkW70+igSfX5vIhwZJcJ/5W6oeTGx9Tz3fdj5ezi6K37A4AS/cr3cH/Gu72HB3zp1AZgr65zl\niWXpdDVJZJ9TCn3tkaP2u5uhvwsOvzQtUzanveBnZmbS2Ng4OaI/NCCRZFomYCZu6fR1SI5x+2ER\nxPodo8/2GAdrLY2NjWRmxpg9euO/w28/PPLicULfsj/+ipv3S6ZMtK3iBN+EYNvdYxewox4GuqVy\nS+Q8+Cuhtqj58rpb4OlvRwqFS8nMngM5c2NHhG4enQy/4I8Sqbpo3t9pm2gufl9nYstFc8gJ/gTz\nzgd6w5Vrw2sTW5djaFA6RyH2cXvwU/B/10dOXxGL2pfhkc9BWo7cT/HsIeeJl6+Wayde68ot1985\nPstwMmn1lTWRPHxn5yzxRtD7r1dXeXQ3Jx4gHUemfadtZWUl1dXVTMrEagN9Il45Q3JCUjshewJR\nX2+HXPB588EOSXRwuANyxj+yNjMzk8rKypFfHN4isz52NYbXOzQYboaOdlH95TbJlKl+HlZcE/68\nox4wsPxy2P4buOQ/IGWUS6F5v7z2dYhoZhWOvjOuTOl5Izu1tt0DD38GFr8xPPrSiUZ2MeSVxe4I\nc1FUet44I/w8+YPELJ1X7ob7/hFuelnKEgtrYesv4eSrIT07/Nmw4McQjT2PQl45lK0YuwzN++V6\nAkn/mwwa90jkmZop176fwX7vs2b405fij3fp7YC7/0aO/xs/BQ98UsQu1vXeWi0VeGGVvG+vi51g\n0HZYWm19HVC7BUpPnMheHhuth+S4zDlRjlFf5+id5a7DdukF8Mqv5HotWSqfuQoMJMovWpS8ch8D\n017w09LSWLx48eSsbNs98Me/gQ/9Be7+ZyhdDu/4afj75gNicSSaLfDw56R5+5kjklJ2/0dlG/+0\nb3IG+LQfCXcKNe4J31htNWE7Kp6l09UEW7zsougIv91rjq68Tprm+5+CpaPM9+MEH+QGHVPwDwAG\nKtZK6yfWutpqwoLvIs6sYqk8Y1VifU7Ac8NZP6MJfo8vwg+leKNtExD8Lb+QiHT/U/GvgyNb4Tcf\nlON47sfks9ZDYkWlpMceWXrfP0L5GnjXXWOX4ehueU3PnbwI33XYLtwAh6JsPHccc0rh+e/LdVGx\nduQ6Hv8PicLfez+E0uSz9iNQdsrIZdtqoKAiXGl2HIkt5m2HYdE58PoT0npYed2x7d9EaK2GgkrI\nnSvvOxtGF/z6HTK2w03B4LcgXYQPIvinvHns7bccErchVmbaJDPtLZ1JxYlNURVkFY1M03vhh3DP\nBxJv+je/LjW4yx8+6UqJVF5/cnLK6+/I8jd3ncinZoW9/Gg23SnCZUIjRbejHnLLYNnFEjFvu2f0\ncvi34Y9g4tF8QIS7aNHIaN2dA/+N4Y/wc8eK8P2CP5ql41UQzr/PSGACta4mER6AA0/HX84df/9x\nc/79kvPFFvBbVoMDEgk7S2UsnH+/7E3QsDOx34zFka1SGS3YIPaJv7/JtUgu/LyI/u8/JmWOZt8T\nEhgsfmNYHON1yLbWQMECOZ8Qf3qFthooXAhlp0prdipoqxHBz/HGaIyVmln/KsxdIfM6wUhLJ5QG\n81aK4CfCU/8NdxyfCRaDJfhNr4tHnJErUWp009YJTaIdZc37I2vlxW8Ub3PnA4n9vr9n9I6q2pcB\nAyYFmnyC7wR44ZmxI/yBXnj+Dlh6odx0sTz83LkygOmkK+DV+0fvcG7eH56l0i/U8Wg5IGKfVy43\n+mB/5LogsuLoapL9zCyQm6jraOQAOYj08DPyvVz8BDttQYR/rIp85wPScsqvhIPPxF/O2WlHtoaj\n8UPPSmW05K/EjvF7250N8lnLgbE9cvBac3Oh8gzZx444dmZXE/zlm4nljh/ZKllQTqj9laXzrYuX\nwmX/KdfdCz+M/P1gPxx9TaYjAZ+QxxH8thrIrwgvF68S72mVB9TMXyVlTDRrzLF348gWy3hprZZz\nnu21oEfrdLfWE/yTJcpPyYjct9Zq2Z+KtWJRJdTntf+4RPcQNMFv3g/Fnj2UWQjdUQLgLt66bWOv\ny1oR2yKf3ZSWCcsugtceHPvCHRyAH5wPD94cf5nDW6DkBLkYGn0jS5v3S+S+6BwRlmgR2Xav7MtZ\nH5aLL7rj1EX4ILZFTyu88uv45WjeLzekCSUW4bcclKgtfz5gw8fVWl+E7xf8RmlxhVLC5Yru+PR7\n+MZ40yuMJvg+Swe8GTPHEPwd90m5179Pmu3xWhAth7wK0MixBvHvK9eHoz6/aPib/PVREftA38jK\ntnGvnPfS5fI+XpT/zLfhkc/Dd06Xvod44mKtWDrzVoZbRxEVkif4OXNgxZuhfO3IVl/jHklpLjtV\n3mfkSgUXK4W2p1WOf0GFHPfUzNj56u645FeIPdLbJq3mRNn5IPzsrXDXOxOrSGMx0CeCXVAZtkxH\nE/y2GulTK1sh12FeWWSl1+a1bMrXyHFIZH9U8JNE0+thgY5l6bhmZ10C82N0NckFGn2iTrpSLoDD\nm0f//fbfiKiMln9cu0VuhJKl0Lgv/HnzAYlIXEeR3/O2Fp75jgxVX3qBWCt+S8d6Auy81SXnQdlp\ncN+H4Xc3xfa5mw+IAOXOG1l5RDPY7zXTF8m2IRwBdTeHhdhfcXQ3hYXICWa0kPg9fEhA8NtFlF1f\nyliWTnezTOe74hpY6D224eCzsZdtOSjR8KJzJMupp03smgVnSmQOkRaGPwKsj7J1fnMj/CLKt27c\nDXNOCI9LiCX4Q4MyWrpivRzrez4Av7w+dkutrUaO8fxV0k8CkZWZE/zsOSJiC8+SaNvfMnN2lN+v\nzy2LHeG7yjy/QtaXWxa7YnDXgIvwQa75RDj0vHQgFy+VFsoz30nsd9G0HwZs4oLvtGGu1/meN3+k\nh19QIYIPY9s6gwPSYixePPpyk0RwBH+gVy4wd2CzCkUA/F6li0IS8VpdpBp9opa9SSyYnb+P/9uh\nIRlJ6V9PNB0NXsfmKhHbpr3hCM5ZJi4Dwm/rHHwW6l6R6N4YL8KvDf+2u1ly5F0knZIGf/sInP1R\n2Py/8N2zwh18ED5uRVVyIY9l6bQeEvuiyCf4rpJw+5qeF7merqawEA37olERod/Dh7EnUHMTpznG\nsnR2PijHZcVboGKdVBYH4/j4rV4L5tS3Si765p/IPi840+cDx4jwTSjy2hoahD2PSZ+PK1t3i/y2\n5AQ5fhn5sQV/70YRq7M/Ah94BM67Va65PTGeCezOZ7wIv+uolC2rSN5XrJWRp35rs26beNMly8Kf\n5cUZVOWEvKDSt1yMCN9dF/nlEqCkpCc2AKthl1SS+fPh/X+QbKmnvxXf+hqNVl9Z03NkjM5ogYRL\nyXSVsb8yGxqUfSqo9PYnI1Lwm14Pjyx2tFWLjagR/iTTfACw4Qh/eAZF70Yb6PU8fSM35Vjem2uq\nRZ+orCKoOtfzg4ckCvvmakl3c+t87QG5ieetlJstVnPUXfjzV0PxEkkXc8LR7Am+S/nyd6q+/oTs\ng0vDzC+XzlvXX+FuUOflgnj5F/8/EY6+DnmYuKPlkBy3wkUSsY1l6bjKJyLCd+XeL68LN8iN4Wwv\nf4Sf6yL8KIHoixL8rKKxI3zn38PYWTo77pO5fCrWijVXsQ4OxPHxWw7JtMsrrpHK/Yn/AgxUnh6Z\n6eFoPyLfz18V2Xqs3yEVkx2C/X+Wz1xfTckJUmGXnhQ7U2fLz6SSXH6ZpNSe/RHZxpGtI5c98op8\nV3ZK/Ag/uyScfDAcnfpaqXXbJW0xNT38WW6cMROuMneCnzt37Ag/NV2i5rE6bvs64a53SB/O9ffI\nZHgXfl6meXBBVH+PjF+57x9H9tONVdacOaNH+PWvSt+Uqxz9lVn7Ecm2ya+Q/Sk7Jbw/Pa1w56Xw\nmw9Frq/J6YhG+InR3wNPfiV8w8TDCXSxz9KBsK3jTnL5arEPxho04dZXGCPP9qQrJPL73rkyZ01/\nNzz5X1JOa+W1eAmc403CFqvj1TVt568MWzeNe2RdHUckus8ukYjEX9ZDz8uN47JTokV3WPBj5JhX\nrpdOR5dPDuGBXUVVciG3Rg2+euln8PBnfct7ZSlc6IlI2kjBrzpHoml3zLuaw0KUUwqYkYLf2yEd\n4k6UErF0IiL8Ak9cY1Tk3S2w90+w4moRWRBbo3bLyEFYve1yzRQsEHFYer6st+wUOeaZhVIJ+EWj\n44iI3ryVYum4MrgKJZQqETuEs7FcJF26fGQSQVeTBBQrrwtbVuk5IsixIuQjW6UC8ae0RncqZ/ty\n6YuXyPGq8Qv+jpHpl7nz4gu5CYUr73jTK7QdlvOeliXv56+S8o8WbD32/yRKfvv/SDlBRmivuR5e\n+JH0ZXz/DfDEf0qK7ffeEN+ag3AHfH6FvOaUjiH428PRPch91NMq9+Vwy2aBvJavkf0ZGoJH/0Wu\ngyPbIvv3/JmDx4GZL/hYePEn8Md/Hr2jNLomdbnk0ZHvUm9+kLFsneb9ciG7gTd+ll8uN3F3M7zl\nDvjEDlj1btj4Jbj7/XIRnPvxsJDHsnVqt4RvvJIT5LPGvWFBLVok4lS4KFxhDA3JTIgLTg+vJ79c\nXl2mjvOWYwk+SNpey8Hw8v4LsqAisrUA8OL/yMhZt3zLARG8/AoR57z5kevKniND2EGasxAZ4aek\nyk0XbQH0tYf9exDB726Of86jI/zMfGk6x5rw67U/eHaOL2d60dmyfPTUE26OoELvpj71bfK64Ex5\nDYW88kd5+HnzRDC7m8OV2cFn5DgtOU/6D0CyfkwoLABzT5ZWoH8w1yt3Swfqmusjy+YEM5rareHs\nmrQsSeeNyNJpjBw8ZYyIlYvwu5vlXI0Q/LlyXqIrxdYaOe9uMF9emfecg6iJ/toOh4UWJNjqaYmf\nanzwWZmj5vS/k1a0n/NukU7/ez4g27n+XmmxhlLkubpPfyv2Olur5Vpy9/Fogj84IHaSf/Ccv5/K\nVR4F3j6Vr5FgYMvPJU26YKGkxPrnv2reL0GRu0+TzMwX/LQsuOBzcqGPNk1A8+tiB7gL21k6bioE\nF6ksOU9e/Z1r1o4c9t20P36tXLgA/uE5+MiLsOodctFd/S045S3SWZtfCSvfGf59LME//LLYOSDL\np2RIc9+Ju/tt0aLwDXJ0l2QQVJ4RXs/wBen5paNF+BAWLhflN++XbeeWhW9OF8kMDkjEgoUd3gyR\nzQekeTx8s88Lb9tlI7gborVGbs7+rnCLa/g3URFhb0fYzgG5Se2g7K+18PO3w5/+zbd8lIc/2vQK\nW34u5apY5zsOZwBmpK3jKtyChfJ60pVynvwDbHJKIwW6vVbOg+voc1H+wWfE3lpyvnTUtlZLK65w\nUdg6iZWp89JPpbXgRNwxf5WcG7+X3dUkfQ7+Z8pmF0dW2p1HR46WLV8rLYv+7rAN5TJ0HLHy0EEq\nB7+Q58ZbriZS6FzHbaw5ffq7JbGgYAFc9C8jv88vhyv+G879BPzDM3DChVC5Dj74lNheD3829npd\nDr4je078NNd9j8uU1e6+BN/AsrrI/gAIW2O//7hcL1d5s9P6W2zDY3lSYm9zkpn5gg9w2tvlYnns\nX2NPFzw4IFZH0eJwkz3a0nEXY/FSufn9Ef6mO+Fb6yK91LFSqeacEBn9p6TCW38gXutV35QbOqtI\nIvhowR++Sb0bIBSSaL9xb1jcnZXkInxrZQoF8MTKI7rjtP2IRHh+MfQz7zRJo3MzPrr+glAofCG7\nC7txt0T8GIk6Idyh7MifH45om/fLd/neelz2CETOmR+rk6+vc2SE747Vvsdh98Pw2kPh73uiO23j\nzJjZtE9G1a65PvIBHJkFciyiO25boyL8zHz44BMyBsORWxqZVuqP8EEEtOWgVAQLzwoHGfueEMF3\nLToQDx/Cgl/7slg0a25gBO56OeKL8vc/Ja8LNoQ/yyoemYefHSX4FWulhXNkW+wMHQj3V0RXzi5T\nxRG3YjgcKfhlp0lF8eRXR47D2Pjvcmyuvi3yOvCz5nq46AuR32fmw1u+J5XwHz870i5qrQ5bMBD2\n8KOXs1ZsovxKOPkq3zFwfU61sq503+yspSfJvTTUD1d+PRxQ+KfLOI4pmTBbBD8Ugov/TW7G6GlJ\nrZWRg4c3w5m+Z9GOsHS8GzSnVCIZd5FbC5t+DFjJr4eRGT+JkpIm5Vx2UfizoqqRgu/8+3JfJFGy\nVAS/eb8ItrvZChdKs7q7WUQ6qyhSMFLTZZ+c4HfUy29dxRdNarpEd/4I312Qw/aQZ8U4+2DVO6Fm\nkyzrcvAdztIZ7JcboqhKxD01U977p1VwxBpt2+fNhe/wz6fz56/J/w07w0LR2x7ux4DwTRjdcfvS\nz8RCWR3juaSLzpZBPX7xaTlf96ASAAAgAElEQVQo2SQ5c0cu78iZG7YFBr2+itx53kjiedJZ63zl\nhRtESHNKpR+hca940o78Ctnvhtfku/97j+xLrGkfXMTvt3X2PCqtm8r14c+yi8IVrZtHJ1aED3Lf\n1G3zpr2YF7lMrMjd2nCmyvByrmLwndP+Hjl3/pZAajpc/lU5Pk9/M/z59t9IIsHa944+BUg8MvIk\ni+ng0yOz51qjWiM5pSLQ0S3B15+QgOrcj0VOmzLcgq4b2VpISZUMovUfkHs+q1C2VR8t+MenwxZm\ni+CDRFgnXirDlP1Nssf/Q5rAb/wnWOuLiqItnY46uahd77rrIK3dImmOGNj9iCzbchDJ+KmaeLlj\nCr7L0FkV/qxkqTT/mvaJoDrB9mfqVL8gmSLRYu7PFe6oi2/nOBacIWXo75YI37Umcsukb8I/h3lq\nFvyVN0/+ll/I+l26qNt2X7uIsZsvxJhwxk+8CL+zIXIUcm+0h++10HY/LGmN5WvlRm3cHfm0K8fw\nYw59N/LggJT5hItie6gLz5IWjF9AWw9JRDja4/hy5oit4sY8uH0C8X/rtoudk5EvNo8xEuW/9qB4\nvK5vB7xMneXSqXvnJWJ//fX9sZ8illUo4uHKay3s+ZN0xKek+ZbzRfjuNVrw88vlfNdsFgEuOyXG\ndRVD8N3DRPL9gh9juXZfSqafky6X7KcnviKPsTz0PNz7QWmhXPZfI/c5Uda+V/qOHvl8uAIfHiDm\nK+twLn7UBHhP/Jdk56z968jPs4vFg+/wPHx/ywbgbT+AK78Wfl96Uljwu5qkDBrhHyMXfVEiwe9u\ngJ9cDb9+nzTD1twA5/9z5LKp6ZL14bd0nBDOXSGpcg07JTc9NRNO/4BEZd3Nvo7MSaiZi6pErP2d\nj4dfEpH1+9rFS6Wj7sDTkReIE+ParVJev3/vyK+IjPDjzQLpWLhBxHPvRhFIt71Qigi4s3RqX5ao\nsnixbPe573v75Ld0vBvaRbRuXQVexo/LtImO8O1QZOdZXwwPH6TDOLMQLv+KvD+yTVpgQ/0j8/Ah\nMnLb+5hUhLHsERDBh8hpFlxK5mjkzpWKoq8zbHe4SHDuConW9/9ZKlbn3S45T8QcIltoAHNPkoos\nJR3e/1Bkyy8af8ft0V3SGlt6YeQy2cXhitZNqxBt6biO25pNsTN0QM5ZKDX29MB+4cuZI62oiBGp\ncQQfRNhTM2VQ2l3vlHW98xfetObHSEqqpB437ROLFkZ67q6sEDlN8v4/w4G/jIzuIXJgWWtUhB+L\nuSfL+R8aPO4ZOjDbBH/uSZKutfR8EYi9GyWL4spvxLYw/PPp+Eefus6p6k3iTa+4Bk67TiLUvX/y\nZfxUTbzMRVUi5C4Ct1aimgVRwu1EoKclUlCdfbLdG+Lvz9Bx5M/3CX4CEb6rNLb+0iujX8C9yHxo\nSCoZ1wo57dpw5elPVXVRoJuMbNgeqpT1uAjTCTiMHKEL0mkby8Mf6IYzbpSOtJR0sR+i59GB2JbO\n5v+VJvyJl8Y+Dnll0nfiT+tzEf5oDA++qg+f1+EI/xTp+GvcHa5QABb/Vfh//+AmgFPeKhXC3zw0\n9vTB81eJkHQ3i50D0oHpJ6s4nOHkn1YhmvK1Xku3M7bgh0JiX/k9/OHcep/gh1K85Xznc1jwoyJi\nkGP1pi9KJ6sdgvfcDTklI5cbL8suluP86BfgrnfDCz+QzyM8/BgD5574T7lnoqN7f3mb90slkT+W\n4K+Q89/0+shU8ePAtJ8eedysuCZy7vfRyCqKtHTcDVi8WKyKP39dmnxr/1o80Kxi2PVwOP89dxQf\nN1H8mToFFfLaXitRth9/M98vqFmFImavPylRlD/TxJFXLhFdT5u8jiX4OSVSwbz2h8gygkRktVvk\nYu1rD2d/rHgzPHSL3KARHr4vwg+lhm/wggrZz+Fh/VGWDkRGhNERfnquCHwoFc78kERwpSd5gh81\njw74LB3vu4562PUQbPj7yMFE0Sw8S46DtdJy6KiL3L9YOH+/86hP8H0Rvn/djsIFcszbDoeXdZxw\n4UjRjsdwx+0rMuq2ZNnI8mYXy3nqaQkLW3SED5FTJMcSfBg5+MqlrUZHurHmnAFvvqUYrH2vXKtL\nzo+89ieCMfDm22UczJ7HZAAkJvL4RE+gVrtV7q2LvxQeLxBN3jwJBCGBCN91wr8ajvBjjeVJErNP\n8MdDZqFc9NaGOzNBIpK5J4m1UrxE5kwxRrzePY+IT+686IniTnbzfhmQNNyZd3bkcrll4QdFRLcs\nChdJ5kbZqbGzb9xN5Zr6iVRUC84MT9jmvyALKsRrdkPGncDklUlu9MHnIiuU4blxDsuxdBZGfoWI\nTv0Osdb8TWXXzHcZMUODYnf49814I1urzg1Hf/NOk36WYcH3RfjpOTI+wEX4L/1MslDWxInaHAvP\nkrTNo7vk95BAhO+JRke9RLUmJfxZ6XKpmE3KyDnnT/9b8XdH6x8YC3c+Dj4nNsS6941cxtln3c2R\nc+FH4zpuMTJVQCzy5kWOvq55USq86PVFd8S3HYaMgvjZYqEQvOGTsb+bCAUVkh5prYx56DoaaXEO\ne/jecXn1fjlfq94Vf525ZWE7LtrDj8ZlXdW/Kte3m733ODG7LJ3x4iydnlbpaMr1ZSG4iGbNDWFh\nP/ESuUH2PT55vlvBArmgXG1/8BmJ2N2F4TAmPLIw+ik67n1lDDsHwgLqsn/GivAhbCllFUdmu+RX\nyrHau1E6q/xCcPGX4JpvRwqWm84YIo+Zi4SOvDKyAzJ3nrSg3IRx0dMqON7/YGTfTNkpYqO4MRPR\nFURGnpzrnjYZiLP0grEtEr+P3+pGESfg4YNEie3eKFtX0aVlyYjYirUjI8YNfy9phxMhZ46co00/\nkvN0wkUjl/E/T6Azah6diHWVSPRbvCT2AEMYOW3CwWckuyk6GIqeaK3t8NjimEyMkXO/KCqwSs2Q\nishF+DsfkOBrNEvJ3yIbK8JPz5EAqv5VbzLHqmMq/rGigt/dEnv06cKzRGBWvzv82dIL5OYY6Jm8\nE5WaLjeoX/AXbIgd5TkfP7oJ6N5H+/4OZ6scHo/ge5ZS9H66ymPXQ5Jx4rdD5q+M/cQid0NEWEPe\nzd60d6TYDI878FoYbuK0sSIh1/fiWknR0aObXuHZ28UuuOBzo68PxE7IniPrHB5lO4al47cF2mtH\npjO+5ftw1QSFfTTmr/KevpUhrdNohiP8Jolws4rjtyre8Ek456Pxt5XrPb9gaFCy11oPjRRRGJl5\nFT3oajrhcvEb90oL9OQrR1/e30KI1ScRzdwVIvjNB46rfw9BF3xn6cSaUGzVu+ETr0berNnF4Q7N\nycydLVokgt95VKyDRWfFXm7ZxVLp+CNuCFcEbpRsNMOWzjgEf86JIsSuVeFwUVnX0ci00dFwxzAi\nwvfdGLFSDEuWhicSixfhRzOm4OfLcX76WzJ4JtZj/KIxRvpTDj4jYmZSwhVoPFLT5drqbPCSAaJ8\n6vLVYS83Gbjzsuis2JF5RITfMPozmNe9L7Yt5MjzZVS5UckLY1y/w5lXXp9N9KCr6YQTfPcgo+WX\nj768cwZy5ib2aFOXddVWrRH+cSWrULw3N1zeL4Sh0EhhBTjxYnmdzBPlcvGH/fs4gr/6XXDDb0Z+\nvupdkq4Xr3MrI198chcxx/JrowmFJDviws9Hfu7PQkhU8N2N7T9mmQXhgVRZsQT/BDkmg/2+CD+O\n3+vIKRFxdQ+wyYg6fxkFMqCsrwPO/0xiZQc5H837JXsqv3z0B74Pl8WbTydWhJ9s3HmJTsd0uBZV\nd5N41YlcD/HwP/nq4NNyjGN18Lpz/9AtMhCvoz6xaHgqyCkV63bnA9IvNNaDyN35TdSimrtC+o/s\nkAr+ccVd+Ee9KRPGyk8HifxPvVYeLzhZFFWJ97z3MWmGuzk4EiUtM36rAMLz4kN4cFkiVK4febHn\nlIYfYO2fU2Q0YkX4EL5BYkX4xUvlpmg5GH74yVgRPnhi4w2Lj66w3fuV74ic8XAs3LF9/cmxO2wd\nuXO9tNPGkRF+sln8Rjjz7yPtSD+ZhWJNdnmWTvYEUh6Hpxaok9TbhWfGnhdm6YUy2vXV38F3zgDs\n9I7wm/dLcHDSVWMuPnx9J1qB+a+94zjKFoIu+G60bcMuSfFz70cjfz5c+6NwXvdk4IRw272SVplI\ns3C8OFtnotFmKCTrMinxU/Wimb/as4eiWiDuBokX4YP4qIl6+BC2dfxPu3JkFUka53m3JFZux7yV\n0omMHbvD1pEzJzzp2PGO8NOz4bIvx7dqQiHvEZ8JWDpj4WzQum1iR8ZrnYZCctw/9JTYhTDyepgu\nZM/xsm6sTHWeyPIpGYlH6yXLpMKF4x7hBzst082n07BTmqaTkWZ5LLhavqdlZP79ZOF858kYO1C4\nSOyYeHnJ0ay4Rjzz6MhvtAh/WPD3hL8fy9KB8HwysZY99xPylKpjmQOpcv34IvycuTJgCY5/hJ8I\n2cUi9t3NsXPwE8VZOjvuk9dYncR+5p4MH3hYKoh5K0dfdqpwFldRVWJBTSgkD2OZM0bGlyMtUyq7\n1kPHPRgIuOB7lk7LAV/O8RTgr+XjRUgTxUX4iXTYjsXlX5WpCxLFmHAOe0SZvP6AWBF+drG0ohr3\nQIrXBE5PQPDdDRpL8OecIH/HwsKzRPATjvB9vvhkHPPJJqs4nL46kQg/LVNaC7VbZDqEROzIUEri\n/T9TgTseJ12ZeBC4+A3j20bl6XJ9H+cgUy0dkM6Tqbwps4s9MTPxUysnirNPJiPCn3vSyLnYj4Xh\nCD+Gh2yMRPmNe8JZOolYOiXLxM5JpDUwHpacJ6/u4S1jkesT/Oka4Q934k9A8CF871SsT7x/aDpT\nulysP/dwm2RwxVelVXCc0QjfMRlCeKwYA8VVMvovK4F+hGMhbxIj/MmifK1kdcxZFvv7khOkI7Dy\ndGkhpCYweVZKqve4wUnsYwHJLf/w8+EHkoyFi/BDqRPrFE0WWcUyhxNMzNIBSXY4+lrs/PuZyLzT\n4JZD8QebTQbpOclb9ygEW/D9onC8O9aiueJrsW2PycKNAJxO0WbZCrh1lGcHFy+VCdw6GyS6T7T5\n+5bvhzvFJpNExR7C8+nkzpvYVAnJwt9vMpG0TAgHEaNlis00kin2U0iwBT+UIhFmb+vURviQPCvH\nMX+VCOFJY4wanE64cQVHtibm3zvGI8zJwtkkUx1IxMPfup2opVNQKam6sabmVqYVSQ09jDGFxpi7\njTE7jTGvGmOmXwjgLJTpZHUkA2PkyVQTmVP8eOMydeq2H9cJpiYFF0BMV8EfjvBN7Hl0xsNZH5Gp\nm2faOQogyY7wvwk8ZK291hiTDky/dlJWoWTpzHbBn4m4CH+wL7FBV9OJ9Fz5G2syranCZUZlF0/8\nAdo5JZMzX72SdJIm+MaYAuCNwPsArLV9QN9ov5kSMgMS4c9EMvLCsyzOtOjRGHjPr4/7SMqEcRH+\nRP17ZUaRTEtnMdAA/NgY85Ix5ofGmBFd08aYG40xm4wxmxoaGkauJdm45uxUe/hKbJytM9MifJCs\nlXgP+JhqhiP8Cfr3yowimYKfCqwFbrfWrgE6gRFj2q21d1hr11tr15eWTkG0kVuW+Cx3yvHH2TqT\nnVcfdIYjfLVigkQyBb8aqLbWPue9vxupAKYXb7wZbrh3qkuhxMPNtzITI/zpjEb4gSRpgm+tPQIc\nMsa4HLkLgR3J2t4xk1s6OaNGleTgLJ2Z5uFPd9IyYdklMrOmEhiSnaXzEeDnXobOPuD9Sd6eMtuY\nyR7+dOc9v5rqEijHmaQKvrV2C7A+mdtQZjnuIfLxnterKErCBHukrTL9SU2Xh5UrijJhpuEkH4qi\nKEoyUMFXFEUJCCr4iqIoAUEFX1EUJSCo4CuKogQEFXxFUZSAoIKvKIoSEFTwFUVRAoIKvqIoSkBQ\nwVcURQkIKviKoigBQQVfURQlIKjgK4qiBAQVfEVRlICggq8oihIQVPAVRVECggq+oihKQFDBVxRF\nCQgq+IqiKAFBBV9RFCUgqOAriqIEBBV8RVGUgKCCryiKEhBU8BVFUQKCCr6iKEpASEjwjTE3GWPy\njfAjY8xmY8zFyS6coiiKMnkkGuH/jbW2DbgYKAJuAL6ctFIpiqIok06igm+818uBn1prt/s+UxRF\nUWYAiQr+i8aYhxHB/6MxJg8YSl6xFEVRlMkmNcHlPgCsBvZZa7uMMcXA+5NXLEVRFGWySTTCPwt4\nzVrbYoy5Hvgs0Jq8YimKoiiTTaKCfzvQZYxZBXwS2Av8b9JKpSiKokw6iQr+gLXWAtcA37bWfgfI\nS16xFEVRlMkmUQ+/3RhzK5KO+QZjTAhIS16xFEVRlMkm0Qj/HUAvko9/BKgEvpK0UimKoiiTTkKC\n74n8z4ECY8yVQI+1Vj18RVGUGUSiUytcBzwPvB24DnjOGHNtgr9NMca8ZIz5/bEXU1EURZkoiXr4\nnwFOt9bWAxhjSoFHgbsT+O1NwKtA/jGVUFEURZkUEvXwQ07sPRoT+a0xphK4AvjhMZRNURRFmUQS\njfAfMsb8EbjLe/8O4MEEfvcN4J8YJYXTGHMjcCPAwoULEyyOoiiKMl4S7bS9GbgDWOn93WGt/fRo\nv/E6d+uttS+Ose47rLXrrbXrS0tLEyy2oiiKMl4SjfCx1t4D3DOOdZ8DXG2MuRzIBPKNMT+z1l4/\nzjIqiqIok8Cogm+MaQdsrK8Aa62N2xFrrb0VuNVbz3nAp1TsFUVRpo5RBd9aq9MnKIqizBIStnQm\ngrX2ceDx47EtRVEUJTb6EHNFUZSAoIKvKIoSEFTwFUVRAoIKvqIoSkBQwVcURQkIKviKoigBQQVf\nURQlIKjgK4qiBAQVfEVRlICggq8oihIQVPAVRVECggq+oihKQFDBVxRFCQgq+IqiKAFBBV9RFCUg\nqOAriqIEBBV8RVGUgKCCryiKEhBU8BVFUQKCCr6iKEpAUMFXFEUJCCr4iqIoAUEFX1EUJSCo4CuK\nogQEFXxFUZSAoIKvKIoSEFTwFUVRAoIKvqIoSkBQwVcURQkIKviKoigBQQVfURQlIKjgK4qiBAQV\nfEVRlICggq8oihIQVPAVRVECggq+oihKQEia4BtjFhhjNhpjdhhjthtjbkrWthRFUZSxSU3iugeA\nT1prNxtj8oAXjTGPWGt3JHGbiqIoShySFuFba2uttZu9/9uBV4GKZG1PURRFGZ3j4uEbY6qANcBz\nMb670RizyRizqaGh4XgUR1EUJZAkXfCNMbnAPcDHrLVt0d9ba++w1q631q4vLS1NdnEURVECS1IF\n3xiThoj9z6219yZzW4qiKMroJDNLxwA/Al611n4tWdtRFEVREiOZEf45wA3ABcaYLd7f5UncnqIo\nijIKSUvLtNb+GTDJWr+iKIoyPnSkraIoSkBQwVcURQkIKviKoigBQQVfURQlIKjgK4qiBAQVfEVR\nlICggq8oihIQVPAVRVECggq+oihKQFDBVxRFCQgq+IqiKAFBBV9RFCUgqOAriqIEBBV8RVGUgKCC\nryiKEhBU8BVFUQKCCr6iKEpAUMFXFEUJCCr4iqIoAUEFX1EUJSCo4CuKogQEFXxFUZSAoIKvKIoS\nEFTwFUVRAoIKvqIoSkBQwVcURQkIKviKoigBQQVfURQlIKjgK4qiBAQVfEVRlICggq8oihIQVPAV\nRVECggq+oihKQFDBVxRFCQgq+IqiKAFBBV9RFCUgqOAfB4529DIwODTVxVCUacHRjl5+9uwB2nr6\np7oogSOpgm+MudQY85oxZo8x5pZkbms6UtvazS33bOXMf3+Mt97+NPuPdk51kcakf3CIoSE76jLW\nWrYfbuU/H9rJX31lI2/62hNsPtgcd/l9DR386oVD1LR0T3Zxh2nu7KOrb2DS1met5fdbD/O+Hz/P\n03uOTtp6Abr6BujpHxz373r6B/nSAzu46GtPcMeTe4fX0dM/yC+eO8g//PxF/rw78bL2DgyOKxA5\n2tHLgcZjv4a7+wb59p92c95XHuezv93G229/JqFrwlrL3oYOmjr7Rny+raaVFw80H9PxTBZ1bT0x\nK7OhITvlgZ+xdvSb+5hXbEwKsAt4E1ANvAC8y1q7I95v1q9fbzdt2jTubX338T309A8xODTEwJCl\nvCCLdYuKOHl+Pikhg7WWjt4B6tt7OdLaQ21rDyEDK8rzOaE0l9SUED39gxxq6qKlu5+CrDQKs9PI\nSU+ld2CInv5BBgYtWekp5GSkYDBsP9zKy9Wt7KnvoKIwk2VleSyZk0NTZx8HGrvYWtPCrzZVg4Wr\nV5fzyI46BgaH+Le3nMpb1lQOl72rb4Dth9t4+VALu+s6ONjUxcGmLvIyU7lqVTnXrC6nsigbay3N\nXf1UN3exq66DXXXt7D/aSWNnH40dvXT1DTI3P4N5+VnMzc8gPSVEyBgy0kKcUp7P+kXFzCvIjHn8\nrLVsrW7lF88d5P6XDwOwrCyXE8vyKM5JH16msaOP/Y2d7G/soqmzj5SQ4eylJexr6ORIWw83XbiM\nfzhvKakpEkfUtnZz22O7+dWmaga9SmTtwkLOXVZKW3c/1c3dtHb3cebiEi4+pYzTKgowxgyXq7Wr\nnxcPNvFKdRvzCzJZu6iIpaU5GGOGj8fGnfX8dksNf9lzlOz0VK5bv4D3n1PFguLsiP3r7Bukvq2H\nI609VLd0U9PczcDQEOsWFbG+qpj8zLTh5Wtauvn8b7fx2M560lND9A0M8fZ1lXzmipMpzE4f9/UJ\nUpE+uauBe1+q4ZEddWSkhrhu/QJu2LCIyqIsdh5p56VDLXT3DbB6QRGnVRSQlZ4y/PttNa18/Jdb\n2F3fwcnz83m1to25eRlceuo8HthaS2NnHznpKXT2DfKWNRV89oqTOdLWwx9eOcKf9xzl5Pl5XHbq\nfM5aWsIrNXKuf7/1ML0DQ8zJzaAsP4PTKgo4f/lczl02h+z01OFt723o4AdP7uPezTX0DQ6xvCyP\ny06bx3nL51JVkk1BVtrwOWnrHqC9t5+8jDRyM1PpHRjkuX1NPLm7gQdfqaWurZeLV5Rx8Snz+OL9\n28lMT+HO957OguIsXjzQzNbqVnIzUqksyqI0L4Nn9zVy35bD7K7vIDVkOHfZHK5aWU5DRy/3vFjN\n7voOANJTQpxSkc/pVcWcvbSE06uKyclIpad/kJqWbrr7BqksyqIgK83bp06ee72R3XXy+5AxZKen\ncFplAesWFTEnN4OG9l5ePNDEjtp25uVncmJZLsvm5pGflRpxnbprbNOBZu54ch+PvlpHdloK7zh9\nIX9zbhXWwl3PH+RXm6pp7e5jyZxclpXlMi8/EwtYC7kZKXzi4uXHdG0ZY1601q5PaNkkCv5ZwL9Y\nay/x3t8KYK39j3i/OVbBX/H5h+jqGyQlZEgxhj6vFs1JTyEvM42mzr7hz6LJSA1RmJ1GXVvvuLcL\nkJ+ZSlvPyMgyLcVw1apyPn7RiSwozuZwSzcf+78tPL+/iYKsNNJSDCkhw9GOvmExnJObwaKSbBYU\nZVHT0s0L+yVqnpefOWIf0lNDVJVkU5qXQXFOBllpIerbe6lt6aHBs5CGrER/A9765xdkkpuROqKs\n3f2DVDd3k5WWwlWr5pObkcauunZeq2unw7dvhdlpVJXkUDUnm5WVhVxyyjyKc9Jp7e7nc7/dxv0v\nH2Z+QSY53jYONXUxZC3vOXMRb1tbyZO7G3hgay07atvIy0iloiiLzLQUtla3MGShNC9j+IbsGxji\nYFPXiLK6Y9fc1T983CqLsrhmdTk1zd38fmstQ9ayqCSH/sEh+geHaO8ZoKsvMgI0Rm7ywSGLMVBV\nkkNKSG7immaJOj958Ym884yFfGfjHu54ch856SmU5UulaYHBIUv/4BCDQ5aQMaSmGFJDhpAnBhaJ\natt6+unoHcBaKM5J56qV82nu6ufBV2oZGLJkpaXQHRWhpoYMlUVZsi4DBxu7KM5J57+uXcl5y+fy\n3L5Gvvrwa7ywv5kLTprL371hCWsWFvKdjXv43hN7sRYGhiwhA6dVFrKnrp3OvkEyUkP0DgyRk57C\nVavKmZufSX2bBEGbDzTT3jtAemqIisIsnKS93thJWkqIt6+rZElpLn/cdoQXDjThpCMvM5X8zDSO\ndvTSOxB5n4UMDFm5zzYsKeHD55/AGYuLAdhV1877f/wCdW09w9doLM6oKubKVfM53NLD714+PNwq\nWLuwkGvXLaA4J52XDjaz6UAzW6tb6B+0pIYMxTnp1LdH3td5GamketcPQG5G6nAZu/sHh6+pkpx0\nGqNaFI70lBD5WankZaaR6l0zPQODHGrqpjA7jfecuXC4rBYYshYDXHDSXE6Ym8eeerm3Gjv6MIAx\nhtK8DDZ+6ry4x2A0povgXwtcaq39W+/9DcCZ1tp/jFruRuBGgIULF647cODAuLfVPzhEasgMRxnV\nzd1sPtjMiwea6eobpCQ3nTk5GczJS2d+QRbzCzLpGxhi++E2ttW00tzVz6KSbBaVZFOULQLW0tVH\nZ98gmakhMtNSSE0J0d03QGefNINPLMtj1YJCyvIz6egdYHddO/sbO5mTm0FVSQ7zCzKHI13HwOAQ\nv3j+IPsaOukbHGJgcIiy/ExWLyhkZWUhpXkZEcsfaurity/V8HpjJ6V5GZTlZVJemMmJZXksLM4e\nsf54x2bH4TY2HWjmleqWmBWfwbBhSTHXrKmIiHTHy/0vH+aP24+I0gFzctP52zcsiYi2QSqhzLRw\n9NrU2cefdtbz9J6jw4JhDCwvy2NdVRGrKguHBemlQy0AFOekUZSdzuoFhaxbVDQccdW19fDzZw/w\nemMX6Skh0lMNOempzM3PkGOYn0llYTbzCjIZHLK8dKiZ519vkkjRK3d+Vhr/cN7SiHLvONzGD/+8\nL8I6SAmFSAtJxT1kYWBoiIFBiyV8T2WlpXqCmMrKykL+ankpad55q2/r4ZcvHKKxs481CwtZu7CI\n7PQUthxq4aWDLRzwKmKt8o0AAAdXSURBVEwszM3P4KMXLKMoJ9zCsNbS3T8YEY0D7K5r56fPHuDk\n+flcvKKMktwMevoHeXJXA0/sauCU8gKuXl0+ovLvGxhi0/4m/rSznrr2Xqy1DFnLsrl53HDWIubk\nhq/P+rYeNh9sobq5i0NNXbR29w8f37zMVDp6B2nv6WdoyHLG4hLWVxVFnHNHQ3sv39m4h9K8DNYt\nknPdNzBEdUsXtS09nDQ/j8qiyNba1upW8rPSWDwnZ8T6uvsG2XSgib/saaSxo5fKomwWFGeRnZ5C\ndXM3h5q66OkfYu2iQs5YXEJVSfbwtdPTP8i2mlY2HWhmd10Hy+flsm5RMaeU59PQ3suuunb21HfQ\n3NVPW08/bd39cn4I30PXrlsw3DKrbe3mF88dJC0lxLXrKikvzBpR3slgRgm+n2ON8BVFUYLKeAQ/\nmZ22NcAC3/tK7zNFURRlCkim4L8ALDPGLDbGpAPvBO5P4vYURVGUURjZgzdJWGsHjDH/CPwRSAHu\ntNZuT9b2FEVRlNFJmuADWGsfBB5M5jYURVGUxNCRtoqiKAFBBV9RFCUgqOAriqIEBBV8RVGUgJC0\ngVfHgjGmARj/UFthDjC5s1xNf4K4zxDM/Q7iPkMw93u8+7zIWluayILTSvAngjFmU6KjzWYLQdxn\nCOZ+B3GfIZj7ncx9VktHURQlIKjgK4qiBITZJPh3THUBpoAg7jMEc7+DuM8QzP1O2j7PGg9fURRF\nGZ3ZFOEriqIoo6CCryiKEhBmvOAH5UHpxpgFxpiNxpgdxpjtxpibvM+LjTGPGGN2e69FU13WycYY\nk2KMeckY83vv/WJjzHPeOf+lN/32rMIYU2iMudsYs9MY86ox5qzZfq6NMR/3ru1txpi7jDGZs/Fc\nG2PuNMbUG2O2+T6LeW6NcJu3/1uNMWsnsu0ZLfjeg9K/A1wGrADeZYxZMbWlShoDwCettSuADcCH\nvX29BXjMWrsMeMx7P9u4CXjV9/4/ga9ba08AmoEPTEmpkss3gYestScBq5D9n7Xn2hhTAXwUWG+t\nPRWZUv2dzM5z/T/ApVGfxTu3lwHLvL8bgdsnsuEZLfjAGcAea+0+a20f8H/ANVNcpqRgra211m72\n/m9HBKAC2d+feIv9BHjz1JQwORhjKoErgB967w1wAXC3t8hs3OcC4I3AjwCstX3W2hZm+blGpmvP\nMsakAtlALbPwXFtrnwSaoj6Od26vAf7XCs8ChcaY+ce67Zku+BXAId/7au+zWY0xpgpYAzwHlFlr\na72vjgBlU1SsZPEN4J8A9/T1EqDFWjvgvZ+N53wx0AD82LOyfmiMyWEWn2trbQ3wVeAgIvStwIvM\n/nPtiHduJ1XjZrrgBw5jTC5wD/Axa22b/zsrObazJs/WGHMlUG+tfXGqy3KcSQXWArdba9cAnUTZ\nN7PwXBch0exioBzIYaTtEQiSeW5nuuAH6kHpxpg0ROx/bq291/u4zjXxvNf6qSpfEjgHuNoYsx+x\n6y5AvO1Cr9kPs/OcVwPV1trnvPd3IxXAbD7XFwGvW2sbrLX9wL3I+Z/t59oR79xOqsbNdMEPzIPS\nPe/6R8Cr1tqv+b66H3iv9/97gfuOd9mShbX2VmttpbW2Cjm3f7LWvgfYCFzrLTar9hnAWnsEOGSM\nWe59dCGwg1l8rhErZ4MxJtu71t0+z+pz7SPeub0f+GsvW2cD0OqzfsaPtXZG/wGXA7uAvcBnpro8\nSdzPc5Fm3lZgi/d3OeJpPwbsBh4Fiqe6rEna//OA33v/LwGeB/YAvwYyprp8Sdjf1cAm73z/Fiia\n7eca+CKwE9gG/BTImI3nGrgL6afoR1pzH4h3bgGDZCLuBV5BspiOeds6tYKiKEpAmOmWjqIoipIg\nKviKoigBQQVfURQlIKjgK4qiBAQVfEVRlICggq8ok4Ax5jw3m6eiTFdU8BVFUQKCCr4SKIwx1xtj\nnjfGbDHGfN+ba7/DGPN1by72x4wxpd6yq40xz3rzkP/GN0f5CcaYR40xLxtjNhtjlnqrz/XNYf9z\nb8SookwbVPCVwGCMORl4B3COtXY1MAi8B5moa5O19hTgCeAL3k/+F/i0tXYlMsrRff5z4DvW2lXA\n2cioSZAZTD+GPJthCTIXjKJMG1LHXkRRZg0XAuuAF7zgOwuZpGoI+KW3zM+Ae7056QuttU94n/8E\n+LUxJg+osNb+BsBa2wPgre95a221934LUAX8Ofm7pSiJoYKvBAkD/MRae2vEh8Z8Lmq5Y51vpNf3\n/yB6fynTDLV0lCDxGHCtMWYuDD9HdBFyH7gZGd8N/Nla2wo0G2Pe4H1+A/CElaeNVRtj3uytI8MY\nk31c90JRjhGNQJTAYK3dYYz5LPCwMSaEzFb4YeQBI2d439UjPj/INLXf8wR9H/B+7/MbgO8bY/7V\nW8fbj+NuKMoxo7NlKoHHGNNhrc2d6nIoSrJRS0dRFCUgaISvKIoSEDTCVxRFCQgq+IqiKAFBBV9R\nFCUgqOAriqIEBBV8RVGUgPD/AVC4xI0NkZYUAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jBooCI0HgSs"
      },
      "source": [
        "!pip install --upgrade --quiet PyDrive\n",
        "# para conectar com o Google Drive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUYnz8PuZcBx"
      },
      "source": [
        "# Importando imagens de teste do drive\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1sbjcK__NABa7gfsPOt7JM8jAaXCLCfKW'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste1_cytHigh-grade Squamous Intraepithelial Lesion - 14659.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1vDBjgozlaLg0tcGQ50b9wpOBz_NYyx8o'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste2_cyt14721.jpg')\n",
        "\n",
        "link = 'https://drive.google.com/open?id=14mCco19UM0k83Irdz3xk2lQaOs7a1YuK'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('teste3_cytoCandida - 7557.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWDU9793LRl7",
        "outputId": "b2a68e26-9661-4558-8975-f4dceec0a315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Testando o modelo\n",
        "\n",
        "test_image = image.load_img('teste1_cytHigh-grade Squamous Intraepithelial Lesion - 14659.jpg', target_size = (200, 200))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "\n",
        "if result[0][0] == 0:\n",
        "    diagnostico = 'Carcinoma'\n",
        "elif result[0][0] == 1:\n",
        "    diagnostico = 'Normal'\n",
        "else:\n",
        "    diagnostico = 'Outros problemas'\n",
        "    \n",
        "print ('DiagnÃ³stico:', diagnostico)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DiagnÃ³stico: Normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n26lVeQyH8kN"
      },
      "source": [
        "# Salvando o modelo no drive\n",
        "\n",
        "uploaded = drive.CreateFile({'title': 'model.h5'})\n",
        "uploaded.SetContentFile('model.h5')\n",
        "uploaded.Upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NMU__WBIQx_"
      },
      "source": [
        "# Importando o modelo do drive\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1b8QkLS1nix4K5g46SGFAR4Cnx1D6eoF1'\n",
        "fluff, id = link.split('=')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}